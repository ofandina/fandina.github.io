{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orafandina/orafandina.github.io/blob/main/Embedding_General_Metrics_into_Low_Dim_Space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4tADaSBofG3"
      },
      "source": [
        "## An Approximation Algorithm for Dimesnionality Reduction \n",
        "\n",
        "*O. N. Fandina, July 2019* \n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "The code below is the implementation of the approximation algorithm with provable guarantees, as appears\n",
        "in our paper [Dimensionality Reduction: theoretical perspective on practical measures](https://proceedings.neurips.cc/paper/2019/file/94f4ede62112b790c91d5e64fdb09cb8-Paper.pdf), NeurIPS 2019. \n",
        "<br>\n",
        "<br>\n",
        "The input to the algorithm is a finite metric space $\\;X$, given by the matrix of the pairwise distances; an integer $\\;k \\geq 3$, denoting the target dimension; and parameter $\\;q \\geq 1$, denoting the desired moment in the loss function. \n",
        "\n",
        "The algorithm computes an embedding $\\;F: X \\to \\ell_2^k$ into a $\\;k\\;$- dimensional Euclidean space with \n",
        "<br>\n",
        "<br>\n",
        "> $l_q$-distortion$(F) =(1+O(q/k))*OPT$\n",
        "\n",
        "<br>\n",
        "\n",
        "where $\\;OPT\\;$ is the $\\;l_q$-distortion of the **optimal** embedding of $\\;X$ into a $\\;k\\;$ - dimensional Euclidean space.\n",
        "\n",
        "<br>  \n",
        "\n",
        "The algorithm works in two steps: \n",
        "\n",
        "1. First, we compute an optimal embedding of $X$ into a high dimensional Euclidean space. The optimality is in the sense of preserving the $l_q$ - distortion. In this step the dimension of the resulting vectors is not restricted, and will be of dimesnion $n$ which is the number of the points in the input metric space $X$. To find such an embedding, we write the appropriate convex optimization program and solve it with the solver implemnted in the cvxpy python package.   \n",
        "\n",
        "   \n",
        "2. Next, we aplly the JL projection method to reuce the dimesnion of the output set from the first setp. We embed the vectors into $k$ - dimensions. \n",
        "\n",
        "We give here the implementation for optimizing the lq_distortion, while optimizing for the other measures is done similarly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_Y0zdK9ofG9"
      },
      "source": [
        "## Setting up \n",
        "\n",
        "To run the code in colab, mount the drive and install cvxpy package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxbQtNB6fWzO",
        "outputId": "bffaf1e8-81cf-400f-9df6-b250a8d7e31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (1.0.31)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (3.2.0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (2.0.10)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (1.21.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy) (0.70.13)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (1.7.3)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (0.6.2.post0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy) (0.1.5.post2)\n",
            "Requirement already satisfied: dill>=0.3.5.1 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy) (0.3.5.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%pip install cvxpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzzM0xdvofG-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "import scipy.spatial\n",
        "import math\n",
        "import sys\n",
        "import cvxpy as cp\n",
        "from numpy import linalg as LA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNL-WWMdofHA"
      },
      "source": [
        "## Setting up the random projection method\n",
        "We use the projection matrix with the i.i.d. Gaussian entries. The input is the metric space, given as the matrix of hig-dimesnioal vectors in the rows, and the traget dimension $k$. The ouput is the $k$ - dimensional representation of the input space, stored as the rows in the output matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Ehn_v4I9ofHA"
      },
      "outputs": [],
      "source": [
        "def JL_transf(space, k):\n",
        "    transformer = GaussianRandomProjection(k)\n",
        "    result=transformer.fit_transform(space)\n",
        "    return(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6b9Aw8kofHB"
      },
      "source": [
        "We also implement a small function that adds a row of zeros to an input matrix. We will use it in our approximation algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "c8glwv_nofHB"
      },
      "outputs": [],
      "source": [
        "def add_first_zero_row(matrix):\n",
        "    [size, dim]=matrix.shape\n",
        "    new_matrix=np.zeros((size+1, dim))\n",
        "    for i in range(1,size+1):\n",
        "        for j in range(dim):\n",
        "            new_matrix[i,j]=matrix[i-1,j]\n",
        "    return(new_matrix);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICYWwfXYofHD"
      },
      "source": [
        "## Approximation algorithm\n",
        "\n",
        "\n",
        "**Input:** a metric space on $n$ points, given as a matrix of pairwise Euclidean distances; a traget dimension $k \\geq 3$; parameter $q$ desribing the moment of the distorin to be approximated. \n",
        "\n",
        "**Output:** the set of $k$-dimensional vectors, such that their pairwise Euclidean distances are preserved up to a small multiplicative error, on average. I.e., an embedding of the input distances into $k$-dimensions with near optimal $l_q$-distortion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Ilh4bPj5ofHE"
      },
      "outputs": [],
      "source": [
        "def Approx_Algo(input_dists, new_dim, q):\n",
        "    [rows, cols]=input_dists.shape\n",
        "    print(\"the metric space to embedd is\", input_dists)\n",
        "    #Step1: convex optimization, using the implementation in package cvxpy.\n",
        "\n",
        "    #Normalize the input metric by the largest dsiatnce (this should not change the optimal embedding,\n",
        "    #but this helps to speed up the computations and make them more precise).\n",
        "    max_dist=np.amax(input_dists)\n",
        "    div_input_dists=np.divide(input_dists, max_dist)\n",
        "\n",
        "    G=cp.Variable((rows-1,rows-1), PSD=True)\n",
        "\n",
        "    #Z i sthe matrix of the new dists, squared\n",
        "    Z=cp.Variable((rows,rows),symmetric=True)\n",
        "\n",
        "    #E is the matrix of expansions, squared\n",
        "    E=cp.Variable((rows, rows), symmetric=True)\n",
        "\n",
        "    #C is the matrix of contractions, squared\n",
        "    C=cp.Variable((rows, cols), symmetric=True)\n",
        "    C=cp.inv_pos(E)\n",
        "\n",
        "    #M is the matrix of distortions, squared\n",
        "    M=cp.Variable((rows, cols),symmetric=True)\n",
        "    M=cp.maximum(E, C)\n",
        "\n",
        "\n",
        "    one=cp.Parameter()\n",
        "    one.value=1\n",
        "\n",
        "    #the constraints describe the convex boundary set\n",
        "    constraints=[]\n",
        "    for j in range(1,rows):\n",
        "        constraints=constraints+[Z[0,j]==G[j-1,j-1]]\n",
        "\n",
        "    for i in range(1, rows):\n",
        "        for j in range(i+1,rows):\n",
        "            constraints=constraints+[Z[i,j]==G[i-1,i-1]+G[j-1,j-1]-2*G[i-1,j-1]]\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(i+1,rows):\n",
        "            constraints=constraints+[Z[i,j]>=0]\n",
        "\n",
        "    for i in range(rows):\n",
        "            constraints=constraints+[E[i,i]==one]\n",
        "\n",
        "\n",
        "    for i in range (rows):\n",
        "        for j in range (i+1, rows):\n",
        "            constraints=constraints+[Z[i,j]==E[i,j]*(div_input_dists[i,j]**2)]\n",
        "\n",
        "\n",
        "    #The optimization objective function is l_q-distortion.\n",
        "    prob=cp.Problem(cp.Minimize(cp.Pnorm(M, p=q/2)),constraints)\n",
        "    prob.solve(verbose=True)\n",
        "    \n",
        "    #After the optimiation step, the matrix G contains the optimal pairwise Euclidean distances\n",
        "    #approximating original pairwise distances. \n",
        "\n",
        "    #Recovering the resulting vectors of the embedding from the distances, by computing eigenvalue decomposition of G.\n",
        "    eig_vals, eig_vectors=np.linalg.eigh(G.value)\n",
        "    num_eigs=len(eig_vals)\n",
        "    D_matrix=np.zeros((num_eigs, num_eigs))\n",
        "    for i in range(num_eigs):\n",
        "         D_matrix[i,i]=math.sqrt(abs(eig_vals[i]))\n",
        "\n",
        "    #The rows of U should be the orthonormal basis of the eig_vectors.\n",
        "    U_matrix=np.transpose(eig_vectors)\n",
        "    the_vectors=np.matmul(D_matrix, U_matrix)\n",
        "\n",
        "    #The original vectors are the cols of the above matrix.\n",
        "    recov_vecs=np.transpose(the_vectors)\n",
        "\n",
        "    #The assumption is that the first vector is mapped to 0 vector. So we bring it back.\n",
        "    vectors=add_first_zero_row(recov_vecs)\n",
        "\n",
        "\n",
        "    #Note:  We could use the Cholesky decomposition of python,\n",
        "    #but there are floating point issues, so we implemented our own decomposition.\n",
        "\n",
        "    #Step 2: embed the high dimimensional vectors into vectors of dimension new_dim, with the JL projection.\n",
        "    #Output is the set of k-dimensional vectors.\n",
        " \n",
        "\n",
        "    low_dim_space=JL_transf(vectors, new_dim)\n",
        "\n",
        "    #Bring the normalization factor back.\n",
        "    real_low_dim_space=low_dim_space*max_dist\n",
        "    return(real_low_dim_space);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-484WU9YofHF"
      },
      "source": [
        "## Generating random non-Euclidean metric spaces and Evaluation functions \n",
        "\n",
        "In the papaer we test our implementation on the synthetically generated data set $X$ of the following form. We first randomly sample $n=100$ vectors, each of dimension $d=100$. This forms a Euclidean metric space. We then add a small random noise to the pairwisw distances in such a way that the reuslting distances represent a valid **non-Euclidean** metric space. \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_space(size, dim):\n",
        "    space=np.zeros((size, dim))\n",
        "    for i in range(size):\n",
        "        sdv=np.random.randint(1,30)\n",
        "        for j in range(dim):\n",
        "            space[i,j]=np.random.normal(0,sdv)\n",
        "    return(space);"
      ],
      "metadata": {
        "id": "nAhOjlJ9x4x4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need a function that computes the pairwise distances of a given metic space: "
      ],
      "metadata": {
        "id": "gDY-CwkDzbGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def space_to_dist(space):\n",
        "    dist=scipy.spatial.distance.pdist(space,metric='euclidean')\n",
        "    matrix_dist=scipy.spatial.distance.squareform(dist)\n",
        "    #answer=np.around(matrix_dist,8)\n",
        "    #print(\"The distances are\", matrix_dist)\n",
        "    return (matrix_dist);"
      ],
      "metadata": {
        "id": "WTZ9qjCjzlGO"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Generates a metric space that is \"epsilon-far\" from a given space. Input: distances matrix of a given m. space. Output: distances matrix.\n",
        "#The resulted metric space itself is not Euclidean. Returns the distances matrix. The algorithm is randomized and it always outputs the metric space.\n",
        "#There is some small probability that the output space is still Euclidean space (if the input space was Euclidean). To reduce this probability we run\n",
        "#the algorithm for several iterations (#iter.)\n",
        "#NOTE: for some runs, the result of is_metric_space(output) can result in False, due to rounding issues.\n",
        "\n",
        "def get_epsilon_far_metric(dists_matrix, epsilon, iter):\n",
        "    copy_dists_matrix=np.copy(dists_matrix)\n",
        "    [rows, cols]=dists_matrix.shape\n",
        "\n",
        "    #COMMENTS: the distorted metric space\n",
        "    generated_metric_dists=np.zeros((rows, cols))\n",
        "    for i in range(rows):\n",
        "        for j in range(i+1, rows):\n",
        "            lower_range=[]\n",
        "            upper_range=[]\n",
        "            for k in range(rows):\n",
        "                if (k!=i and k!=j):\n",
        "                    min_z=min(copy_dists_matrix[i,k], copy_dists_matrix[j,k])\n",
        "                    max_z=max(copy_dists_matrix[i,k], copy_dists_matrix[j,k])\n",
        "                    lower_range.append(max_z-min_z)\n",
        "                    upper_range.append(max_z+min_z)\n",
        "                    continue\n",
        "            lower_array=np.array(lower_range)\n",
        "            upper_array=np.array(upper_range)\n",
        "            min_new=np.amax(lower_range)\n",
        "            max_new=np.amin(upper_range)\n",
        "            r=copy_dists_matrix[i,j]\n",
        "            Finish=False\n",
        "            possible_new_dists=[]\n",
        "            for t in range(iter):\n",
        "                noise=np.random.normal(0, epsilon)\n",
        "                if (noise>=0):\n",
        "                    factor=1+noise\n",
        "                else:\n",
        "                    factor=1/(1-noise)\n",
        "                r_new=factor*r\n",
        "                if (r_new>=min_new and r_new<=max_new):\n",
        "                    Finish=True\n",
        "                    possible_new_dists.append(r_new)\n",
        "            if(Finish==True):\n",
        "                new_dist=possible_new_dists[0]\n",
        "            else:\n",
        "                new_dist=min_new\n",
        "            generated_metric_dists[i,j]=new_dist\n",
        "            generated_metric_dists[j,i]=new_dist\n",
        "            copy_dists_matrix[i,j]=new_dist\n",
        "            copy_dists_matrix[j,i]=new_dist\n",
        "    return(generated_metric_dists)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZE1MdYsWyEGx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next code we just run the above piece as a subrutine, until we get the desured non-Euclidean metric space. We need a function that checks whether a given metric space is a Euclidean space:"
      ],
      "metadata": {
        "id": "sPiKliHAzCy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input: squared dists of the metric space\n",
        "def is_Euclidean_space(sq_dists):\n",
        "    #assuming the dists_space is of a metric space of size=n\n",
        "    [rows,cols]=sq_dists.shape\n",
        "    G_matrix=np.zeros((rows, cols))\n",
        "    for i in range(1,rows):\n",
        "        for j in range(1,cols):\n",
        "            G_matrix[i,j]=(1/2)*(sq_dists[0,i]+sq_dists[0,j]-sq_dists[i,j])\n",
        "    G_row_del=np.delete(G_matrix,0,0)\n",
        "    final_matrix=np.delete(G_row_del,0,1)\n",
        "    answer=is_pos_def(final_matrix)\n",
        "    return(answer);\n",
        "\n",
        "def is_pos_def(X):\n",
        "    return (np.all(np.linalg.eigvalsh(X) >= 0));    "
      ],
      "metadata": {
        "id": "mRhbUY50z3jq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#COMMENTS: from our random space, loop the above code until you get a non-Euclidean result\n",
        "def get_random_epsilon_far_non_Eucl(n, epsilon):\n",
        "    original=get_random_space(n,n)\n",
        "    original_Eucl_dists=space_to_dist(original)\n",
        "    distorted_dists=get_epsilon_far_metric(original_Eucl_dists, epsilon, 5)\n",
        "    while(is_Euclidean_space(distorted_dists**2)==True):\n",
        "        original=get_random_space(n,n)\n",
        "        original_Eucl_dists=space_to_dist(original)\n",
        "        distorted_dists=get_epsilon_far_metric(original_Eucl_dists, epsilon, 2)\n",
        "    return(distorted_dists)"
      ],
      "metadata": {
        "id": "rZ5HU118y-72"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to generate the smaple non-Euclidean metric space $X$, of size $n=100$\n"
      ],
      "metadata": {
        "id": "brKIEXu6x7Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=get_random_epsilon_far_non_Eucl(100, 0.8)\n",
        "#test for being non-Euclidean\n",
        "print(\"Is X a Euclidean metric?\", is_Euclidean_space(X**2)==True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n4hkmGq0pT5",
        "outputId": "f16e9fee-e70e-4eb2-c2d1-665699ae898c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is X a Euclidean metric? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code computes $l_q$-distortion of an embedding of an input metric into an output metric: "
      ],
      "metadata": {
        "id": "7SeIjt8k2PGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#l_q distortion measure\n",
        "def lq_dist(input_dist, embedded_dist, q):\n",
        "    [rows, cols]=input_dist.shape\n",
        "    answer=0\n",
        "    pairs=scipy.special.binom(rows, 2)\n",
        "    for i in range (rows):\n",
        "        for j in range(i+1,cols):\n",
        "            curr=distortion(input_dist[i,j], embedded_dist[i,j])       \n",
        "    return(((answer/pairs))**(1/float(q)));\n",
        "\n",
        "\n",
        "def expans(old, new):\n",
        "    return(new/old);    \n",
        "\n",
        "def contr(old, new):\n",
        "    if(new==0):\n",
        "       sys.exit(\"Contraction of the pair is infinite!\");\n",
        "    return(old/new);    \n",
        "\n",
        "def distortion(old, new):\n",
        "    expansion=expans(old, new)\n",
        "    contraction=contr(old,new)\n",
        "    if (expansion>= contraction):\n",
        "        distort=expansion\n",
        "    else:\n",
        "        distort=contraction\n",
        "    return(distort);\n"
      ],
      "metadata": {
        "id": "yDrcM6zx3n-C"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you are set up to play with the data and the algorithm! Enjoy!"
      ],
      "metadata": {
        "id": "92VJDvLkEmyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_Approx_Algo():\n",
        "  \"Your code for testing\"\n",
        "  return "
      ],
      "metadata": {
        "id": "VJV2E78oEuTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Embedding General Metrics into Low Dim Space.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}